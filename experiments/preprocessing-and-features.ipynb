{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import spacy\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "sys.path.append('..')\n",
    "from utils import cv_kfold, train_validate_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.23.3)\n",
      "Requirement already satisfied: setuptools in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (60.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: jinja2 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.9.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.1)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: colorama in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\learning from data\\assignment1\\assig\\venv\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.4.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'E:\\Learning from Data\\assignment1\\assig\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(filename: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame([\n",
    "        (l.split()[0], l.split()[1], ' '.join(l.split()[3:]))\n",
    "        for l in open(filename, encoding='utf8')\n",
    "        ], columns=['class', 'sent', 'text']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 600)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = read_file('../datasets/train.txt')\n",
    "df_test = read_file('../datasets/test.txt')\n",
    "\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df_train['text'].values\n",
    "y = df_train['class'].values\n",
    "y_sent = df_train['sent'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Features pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TextLength(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([[len(i)] for i in X])\n",
    "\n",
    "class WordCount(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([[len(i.split())] for i in X])\n",
    "    \n",
    "class AverageTokensLength(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([[np.mean([len(j) for j in i.split()])] for i in X])\n",
    "\n",
    "\n",
    "class PredictSentiment(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, X, y_sent):\n",
    "        self.text_to_sentiment = {i: sent for i, sent in zip(X, y_sent)}\n",
    "        self.sent_to_num = {'pos': 1, 'neg': -1, '': 0}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            [self.sent_to_num[self.text_to_sentiment[i]]] for i in X\n",
    "        ])\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "    return [x.orth_ for x in nlp(doc)]\n",
    "\n",
    "def spacy_lemmatizer(doc):\n",
    "    return [x.lemma_ for x in nlp(doc)]\n",
    "\n",
    "def nltk_stems(doc):\n",
    "    return [stemmer.stem(x) for x in doc]\n",
    "\n",
    "def spacy_pos(doc):\n",
    "    return [token.pos_ for token in nlp(doc)]\n",
    "\n",
    "def spacy_ne(doc):\n",
    "    return [ent.label_ for ent in nlp(doc).ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_base_model = ('clf', LinearSVC())\n",
    "_base_vec = ('vec', TfidfVectorizer())\n",
    "\n",
    "features = {\n",
    "    'Baseline': Pipeline([_base_vec, _base_model]),\n",
    "    'Text Length': Pipeline([('feat', FeatureUnion([_base_vec, ('len', TextLength())])), _base_model]),\n",
    "    'Avg Tokens Length': Pipeline([('feat', FeatureUnion([_base_vec, ('avglen', AverageTokensLength())])), _base_model]),\n",
    "    'Word Count':Pipeline([('feat', FeatureUnion([_base_vec, ('wcnt', WordCount())])), _base_model]),\n",
    "    'Sentiment': Pipeline([('feat', FeatureUnion([_base_vec, ('sent', PredictSentiment(X, y_sent))])), _base_model]),\n",
    "    'StopWords Filter': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(stop_words='english'))])), _base_model]),\n",
    "    'NGrams 1-3': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(ngram_range=(1, 3)))])), _base_model]),\n",
    "    'Add CountVectorizer': Pipeline([('feat', FeatureUnion([_base_vec, ('vec2', CountVectorizer())])), _base_model]),\n",
    "    'Spacy Tokenizer': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(tokenizer=spacy_tokenizer))])), _base_model]),\n",
    "    'Spacy Lemmatizer': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(tokenizer=spacy_lemmatizer))])), _base_model]),\n",
    "    'NGrams 1-2 + StopWords Filter + sublinear_tf=True': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(stop_words=\"english\",sublinear_tf=True,ngram_range=(1,2)))])), _base_model]),\n",
    "    'Character-level': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 8), min_df=3))])), _base_model]),\n",
    "    'NLTK Stemming': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(tokenizer=nltk_stems))])), _base_model]),\n",
    "    'Lemmatizing + POS Tags': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(tokenizer=spacy_lemmatizer)), ('posvec', CountVectorizer(tokenizer=spacy_pos))])), _base_model]),\n",
    "    'Lemmatizing + NE Tags': Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(tokenizer=spacy_lemmatizer)), ('nevec', CountVectorizer(tokenizer=spacy_ne))])), _base_model]),\n",
    "    'Lemmatizing + POS Tags + NE Tags':Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(tokenizer=spacy_lemmatizer)), ('nevec', CountVectorizer(tokenizer=spacy_ne)), ('posvec', CountVectorizer(tokenizer=spacy_ne))])), _base_model]),\n",
    "    'Lemmatizing + Text Length + Avg Token Length + Word Count':Pipeline([('feat', FeatureUnion([('vec', TfidfVectorizer(tokenizer=spacy_lemmatizer)), ('num_feat_sc', Pipeline([('num_feat', FeatureUnion([('len', TextLength()), ('avglen', AverageTokensLength()), ('wcnt', WordCount())])), ('sc', StandardScaler())]))])), _base_model])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb140e8c1b1844df8500b0bc28538e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pipelines:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b3270587e2401ca294840308242fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6d37394d494305ae95490a825f0a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e07a136217f4df9b97f5412d447a913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3658ffee2ab14539b770d1f5f4c47365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccc960912ef48d180d95b135600059d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e03d13f25664d309f8cc7b702c75358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f0968cb15844aa96e47a7e5bff90a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651d77ef8412478396b050370dc1a966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae20426909c440adb807c49a3d1e71a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18308c64ba144e04aa7dfd27c2638026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b574758184b4740bc83b7eff3d6ba7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d928a38ab0a4000808f8f81181e25f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287b57d3c69f4b1784cab9ca4c30dca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f671a3f6e694a7b9e499a828a6c2841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7752abb91af8411db55b354b81654c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e84da76cbd042c38c628032e2008e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d114dff1b9114c3eae76d37862f13f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.710176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text Length</th>\n",
       "      <td>0.331296</td>\n",
       "      <td>8.774174</td>\n",
       "      <td>-0.587407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg Tokens Length</th>\n",
       "      <td>0.92037</td>\n",
       "      <td>2.052132</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word Count</th>\n",
       "      <td>0.832222</td>\n",
       "      <td>8.946537</td>\n",
       "      <td>-0.086481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0.919444</td>\n",
       "      <td>0.780888</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StopWords Filter</th>\n",
       "      <td>0.91963</td>\n",
       "      <td>0.592622</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NGrams 1-3</th>\n",
       "      <td>0.918704</td>\n",
       "      <td>5.707091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Add CountVectorizer</th>\n",
       "      <td>0.871481</td>\n",
       "      <td>2.871533</td>\n",
       "      <td>-0.047222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spacy Tokenizer</th>\n",
       "      <td>0.917407</td>\n",
       "      <td>86.671619</td>\n",
       "      <td>-0.001296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spacy Lemmatizer</th>\n",
       "      <td>0.915</td>\n",
       "      <td>83.944733</td>\n",
       "      <td>-0.003704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NGrams 1-2 + StopWords Filter + sublinear_tf=True</th>\n",
       "      <td>0.923889</td>\n",
       "      <td>1.920141</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Character-level</th>\n",
       "      <td>0.918704</td>\n",
       "      <td>9.656025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLTK Stemming</th>\n",
       "      <td>0.488148</td>\n",
       "      <td>2.073308</td>\n",
       "      <td>-0.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatizing + POS Tags</th>\n",
       "      <td>0.897778</td>\n",
       "      <td>177.162612</td>\n",
       "      <td>-0.020926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatizing + NE Tags</th>\n",
       "      <td>0.916296</td>\n",
       "      <td>174.278531</td>\n",
       "      <td>-0.002407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatizing + POS Tags + NE Tags</th>\n",
       "      <td>0.916111</td>\n",
       "      <td>268.151855</td>\n",
       "      <td>-0.002593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatizing + Text Length + Avg Token Length + Word Count</th>\n",
       "      <td>0.915741</td>\n",
       "      <td>95.510956</td>\n",
       "      <td>-0.002963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       score        time  \\\n",
       "Baseline                                            0.918704    0.710176   \n",
       "Text Length                                         0.331296    8.774174   \n",
       "Avg Tokens Length                                    0.92037    2.052132   \n",
       "Word Count                                          0.832222    8.946537   \n",
       "Sentiment                                           0.919444    0.780888   \n",
       "StopWords Filter                                     0.91963    0.592622   \n",
       "NGrams 1-3                                          0.918704    5.707091   \n",
       "Add CountVectorizer                                 0.871481    2.871533   \n",
       "Spacy Tokenizer                                     0.917407   86.671619   \n",
       "Spacy Lemmatizer                                       0.915   83.944733   \n",
       "NGrams 1-2 + StopWords Filter + sublinear_tf=True   0.923889    1.920141   \n",
       "Character-level                                     0.918704    9.656025   \n",
       "NLTK Stemming                                       0.488148    2.073308   \n",
       "Lemmatizing + POS Tags                              0.897778  177.162612   \n",
       "Lemmatizing + NE Tags                               0.916296  174.278531   \n",
       "Lemmatizing + POS Tags + NE Tags                    0.916111  268.151855   \n",
       "Lemmatizing + Text Length + Avg Token Length + ...  0.915741   95.510956   \n",
       "\n",
       "                                                        diff  \n",
       "Baseline                                                 0.0  \n",
       "Text Length                                        -0.587407  \n",
       "Avg Tokens Length                                   0.001667  \n",
       "Word Count                                         -0.086481  \n",
       "Sentiment                                           0.000741  \n",
       "StopWords Filter                                    0.000926  \n",
       "NGrams 1-3                                               0.0  \n",
       "Add CountVectorizer                                -0.047222  \n",
       "Spacy Tokenizer                                    -0.001296  \n",
       "Spacy Lemmatizer                                   -0.003704  \n",
       "NGrams 1-2 + StopWords Filter + sublinear_tf=True   0.005185  \n",
       "Character-level                                          0.0  \n",
       "NLTK Stemming                                      -0.430556  \n",
       "Lemmatizing + POS Tags                             -0.020926  \n",
       "Lemmatizing + NE Tags                              -0.002407  \n",
       "Lemmatizing + POS Tags + NE Tags                   -0.002593  \n",
       "Lemmatizing + Text Length + Avg Token Length + ... -0.002963  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(columns=['score', 'time'], index=features.keys())\n",
    "scorer = lambda *x: metrics.f1_score(*x, average='micro')\n",
    "\n",
    "for features_name, features_pipeline in tqdm(features.items(), total=len(features), desc='Pipelines'):\n",
    "    try:\n",
    "        kfold_result = cv_kfold(features_pipeline, X, y, scorer=scorer, k=5)\n",
    "        df_scores.loc[features_name, 'score'] = kfold_result['oof_score']\n",
    "        df_scores.loc[features_name, 'time'] = kfold_result['mean_time']\n",
    "\n",
    "        # X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "        # validate_results = train_validate_split(features_pipeline, X_train, y_train, X_val, y_val, scorer, verbose=0)\n",
    "        # df_scores.loc[features_name, 'score'] = validate_results['score']\n",
    "        # df_scores.loc[features_name, 'time'] = validate_results['time']\n",
    "    except Exception as e:\n",
    "        df_scores.loc[features_name, 'score'] = None\n",
    "        df_scores.loc[features_name, 'time'] = None\n",
    "\n",
    "df_scores['diff'] = df_scores['score'] - df_scores.loc['Baseline', 'score']\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
